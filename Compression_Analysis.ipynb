{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15a308a",
   "metadata": {},
   "source": [
    "# Universal Data Compression Project\n",
    "\n",
    "## Compare RLE, Huffman, and LZW algorithms across multiple data types\n",
    "\n",
    "This notebook demonstrates compression of:\n",
    "- üìù **Text** files and strings\n",
    "- üñºÔ∏è **Images** (PNG, JPG, BMP)\n",
    "- üé• **Videos** (MP4, AVI)\n",
    "- üìÑ **Documents** (TXT, PDF, DOCX)\n",
    "\n",
    "**Algorithms Implemented:**\n",
    "1. **RLE (Run Length Encoding)** - Best for repetitive data\n",
    "2. **Huffman Coding** - Best for text with varying frequencies\n",
    "3. **LZW (Lempel-Ziv-Welch)** - Best for patterns and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from heapq import heappush, heappop, heapify\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25ee51",
   "metadata": {},
   "source": [
    "## üìö Algorithm Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# RLE (Run Length Encoding)\n",
    "# ========================================\n",
    "\n",
    "def rle_compress(data):\n",
    "    \"\"\"Compress data using Run Length Encoding.\"\"\"\n",
    "    if not data:\n",
    "        return []\n",
    "    \n",
    "    compressed = []\n",
    "    prev = data[0]\n",
    "    count = 1\n",
    "    \n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] == prev:\n",
    "            count += 1\n",
    "        else:\n",
    "            compressed.append((prev, count))\n",
    "            prev = data[i]\n",
    "            count = 1\n",
    "    \n",
    "    compressed.append((prev, count))\n",
    "    return compressed\n",
    "\n",
    "\n",
    "def rle_decompress(compressed_data):\n",
    "    \"\"\"Decompress RLE data.\"\"\"\n",
    "    decompressed = []\n",
    "    for value, count in compressed_data:\n",
    "        decompressed.extend([value] * count)\n",
    "    return decompressed\n",
    "\n",
    "\n",
    "print(\"‚úÖ RLE algorithms ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e98d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Huffman Coding\n",
    "# ========================================\n",
    "\n",
    "class HuffmanNode:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "\n",
    "def build_huffman_tree(data):\n",
    "    \"\"\"Build Huffman tree from data.\"\"\"\n",
    "    freq = defaultdict(int)\n",
    "    for char in data:\n",
    "        freq[char] += 1\n",
    "    \n",
    "    if len(freq) == 0:\n",
    "        return None\n",
    "    if len(freq) == 1:\n",
    "        return HuffmanNode(list(freq.keys())[0], list(freq.values())[0])\n",
    "    \n",
    "    heap = [HuffmanNode(ch, fr) for ch, fr in freq.items()]\n",
    "    heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "        node1 = heappop(heap)\n",
    "        node2 = heappop(heap)\n",
    "        merged = HuffmanNode(None, node1.freq + node2.freq)\n",
    "        merged.left = node1\n",
    "        merged.right = node2\n",
    "        heappush(heap, merged)\n",
    "    \n",
    "    return heap[0]\n",
    "\n",
    "\n",
    "def build_codes(node, prefix=\"\", code_map=None):\n",
    "    \"\"\"Build Huffman codes from tree.\"\"\"\n",
    "    if code_map is None:\n",
    "        code_map = {}\n",
    "    if node is None:\n",
    "        return code_map\n",
    "    if node.char is not None:\n",
    "        code_map[node.char] = prefix if prefix else \"0\"\n",
    "    build_codes(node.left, prefix + \"0\", code_map)\n",
    "    build_codes(node.right, prefix + \"1\", code_map)\n",
    "    return code_map\n",
    "\n",
    "\n",
    "def huffman_compress(data):\n",
    "    \"\"\"Compress data using Huffman coding.\"\"\"\n",
    "    if not data:\n",
    "        return (\"\", {})\n",
    "    root = build_huffman_tree(data)\n",
    "    codes = build_codes(root)\n",
    "    encoded = ''.join([codes[item] for item in data])\n",
    "    return (encoded, codes)\n",
    "\n",
    "\n",
    "def huffman_decompress(encoded_data, codes):\n",
    "    \"\"\"Decompress Huffman encoded data.\"\"\"\n",
    "    if not encoded_data:\n",
    "        return \"\"\n",
    "    reverse_codes = {v: k for k, v in codes.items()}\n",
    "    decoded = []\n",
    "    buffer = \"\"\n",
    "    for bit in encoded_data:\n",
    "        buffer += bit\n",
    "        if buffer in reverse_codes:\n",
    "            decoded.append(reverse_codes[buffer])\n",
    "            buffer = \"\"\n",
    "    return decoded\n",
    "\n",
    "\n",
    "print(\"‚úÖ Huffman algorithms ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae72cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# LZW (Lempel-Ziv-Welch)\n",
    "# ========================================\n",
    "\n",
    "def lzw_compress(data):\n",
    "    \"\"\"Compress data using LZW algorithm.\"\"\"\n",
    "    if not data:\n",
    "        return []\n",
    "    \n",
    "    dict_size = 256\n",
    "    dictionary = {chr(i): i for i in range(dict_size)}\n",
    "    w = \"\"\n",
    "    result = []\n",
    "    \n",
    "    for c in data:\n",
    "        wc = w + c\n",
    "        if wc in dictionary:\n",
    "            w = wc\n",
    "        else:\n",
    "            result.append(dictionary[w])\n",
    "            dictionary[wc] = dict_size\n",
    "            dict_size += 1\n",
    "            w = c\n",
    "    \n",
    "    if w:\n",
    "        result.append(dictionary[w])\n",
    "    return result\n",
    "\n",
    "\n",
    "def lzw_decompress(compressed_data):\n",
    "    \"\"\"Decompress LZW compressed data.\"\"\"\n",
    "    if not compressed_data:\n",
    "        return \"\"\n",
    "    \n",
    "    dict_size = 256\n",
    "    dictionary = {i: chr(i) for i in range(dict_size)}\n",
    "    compressed = list(compressed_data)\n",
    "    \n",
    "    w = chr(compressed.pop(0))\n",
    "    result = w\n",
    "    \n",
    "    for k in compressed:\n",
    "        if k in dictionary:\n",
    "            entry = dictionary[k]\n",
    "        elif k == dict_size:\n",
    "            entry = w + w[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Bad compressed key: {k}\")\n",
    "        \n",
    "        result += entry\n",
    "        dictionary[dict_size] = w + entry[0]\n",
    "        dict_size += 1\n",
    "        w = entry\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"‚úÖ LZW algorithms ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b009882",
   "metadata": {},
   "source": [
    "## üî¨ Performance Measurement Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithm(name, compress_func, decompress_func, data, is_huffman=False, is_rle=False):\n",
    "    \"\"\"Test a compression algorithm and measure performance.\"\"\"\n",
    "    \n",
    "    # Compression\n",
    "    start = time.time()\n",
    "    compressed = compress_func(data)\n",
    "    comp_time = time.time() - start\n",
    "    \n",
    "    # Decompression\n",
    "    start = time.time()\n",
    "    if is_huffman:\n",
    "        encoded, codes = compressed\n",
    "        decompressed = decompress_func(encoded, codes)\n",
    "        comp_size = len(encoded)\n",
    "    elif is_rle:\n",
    "        decompressed = decompress_func(compressed)\n",
    "        comp_size = len(compressed) * 2  # (value, count) pairs\n",
    "    else:\n",
    "        decompressed = decompress_func(compressed)\n",
    "        comp_size = len(str(compressed))\n",
    "    decomp_time = time.time() - start\n",
    "    \n",
    "    # Calculate metrics\n",
    "    orig_size = len(data)\n",
    "    ratio = comp_size / orig_size if orig_size > 0 else 1\n",
    "    space_saving = ((orig_size - comp_size) / orig_size * 100) if orig_size > 0 else 0\n",
    "    \n",
    "    # Verify correctness\n",
    "    if isinstance(data, str):\n",
    "        is_correct = (decompressed == data) or (''.join(decompressed) == data)\n",
    "    else:\n",
    "        is_correct = (list(decompressed) == list(data))\n",
    "    \n",
    "    return {\n",
    "        'Algorithm': name,\n",
    "        'Original Size': orig_size,\n",
    "        'Compressed Size': comp_size,\n",
    "        'Compression Ratio': round(ratio, 4),\n",
    "        'Space Saving %': round(space_saving, 2),\n",
    "        'Compression Time (s)': round(comp_time, 6),\n",
    "        'Decompression Time (s)': round(decomp_time, 6),\n",
    "        'Correct': '‚úì' if is_correct else '‚úó'\n",
    "    }\n",
    "\n",
    "\n",
    "def run_comparison(data, data_str, title=\"Compression Test\"):\n",
    "    \"\"\"Run all three algorithms and compare results.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test RLE\n",
    "    results.append(test_algorithm(\"RLE\", rle_compress, rle_decompress, data, is_rle=True))\n",
    "    \n",
    "    # Test Huffman\n",
    "    results.append(test_algorithm(\"Huffman\", \n",
    "                                 lambda d: huffman_compress(data_str),\n",
    "                                 lambda c: huffman_decompress(c[0], c[1]),\n",
    "                                 data_str, is_huffman=True))\n",
    "    \n",
    "    # Test LZW\n",
    "    results.append(test_algorithm(\"LZW\", lzw_compress, lzw_decompress, data_str))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    display(df)\n",
    "    \n",
    "    # Find best performers\n",
    "    print(f\"\\nüìä Best Performers:\")\n",
    "    best_ratio = df.loc[df['Compression Ratio'].idxmin()]\n",
    "    print(f\"   üèÜ Best Compression: {best_ratio['Algorithm']} (ratio: {best_ratio['Compression Ratio']})\")\n",
    "    \n",
    "    best_speed = df.loc[df['Compression Time (s)'].idxmin()]\n",
    "    print(f\"   ‚ö° Fastest Compression: {best_speed['Algorithm']} ({best_speed['Compression Time (s)']}s)\")\n",
    "    \n",
    "    best_decomp = df.loc[df['Decompression Time (s)'].idxmin()]\n",
    "    print(f\"   üîÑ Fastest Decompression: {best_decomp['Algorithm']} ({best_decomp['Decompression Time (s)']}s)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_comparison(df, title=\"\"):\n",
    "    \"\"\"Create visualization of compression results.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'Compression Analysis - {title}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Compression Ratio\n",
    "    axes[0, 0].bar(df['Algorithm'], df['Compression Ratio'], color='steelblue', alpha=0.7)\n",
    "    axes[0, 0].set_ylabel('Ratio (lower is better)')\n",
    "    axes[0, 0].set_title('Compression Ratio')\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(df['Compression Ratio']):\n",
    "        axes[0, 0].text(i, v, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Space Savings\n",
    "    axes[0, 1].bar(df['Algorithm'], df['Space Saving %'], color='green', alpha=0.7)\n",
    "    axes[0, 1].set_ylabel('Percentage')\n",
    "    axes[0, 1].set_title('Space Savings %')\n",
    "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(df['Space Saving %']):\n",
    "        axes[0, 1].text(i, v, f'{v:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Compression Time\n",
    "    axes[1, 0].bar(df['Algorithm'], df['Compression Time (s)'], color='coral', alpha=0.7)\n",
    "    axes[1, 0].set_ylabel('Time (seconds)')\n",
    "    axes[1, 0].set_title('Compression Time')\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(df['Compression Time (s)']):\n",
    "        axes[1, 0].text(i, v, f'{v:.6f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Decompression Time\n",
    "    axes[1, 1].bar(df['Algorithm'], df['Decompression Time (s)'], color='purple', alpha=0.7)\n",
    "    axes[1, 1].set_ylabel('Time (seconds)')\n",
    "    axes[1, 1].set_title('Decompression Time')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(df['Decompression Time (s)']):\n",
    "        axes[1, 1].text(i, v, f'{v:.6f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Performance measurement functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca371ad",
   "metadata": {},
   "source": [
    "## üß™ Test 1: Text String Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with user input or sample text\n",
    "sample_text = \"AAAABBBBBCCCCCDDDDDEEEEE\" * 50\n",
    "\n",
    "print(f\"Sample text length: {len(sample_text)} characters\")\n",
    "print(f\"Preview: {sample_text[:100]}...\")\n",
    "\n",
    "data = [ord(c) for c in sample_text]\n",
    "df1 = run_comparison(data, sample_text, \"Highly Repetitive Text\")\n",
    "plot_comparison(df1, \"Highly Repetitive Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3fd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with mixed content\n",
    "mixed_text = \"The quick brown fox jumps over the lazy dog. \" * 100 + \"1234567890!@#$%^&*()\" * 50\n",
    "\n",
    "print(f\"Mixed text length: {len(mixed_text)} characters\")\n",
    "\n",
    "data = [ord(c) for c in mixed_text]\n",
    "df2 = run_comparison(data, mixed_text, \"Mixed Content Text\")\n",
    "plot_comparison(df2, \"Mixed Content Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb014d3",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Test 2: Image Compression\n",
    "\n",
    "Upload an image file or use a sample image to test compression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample image or load your own\n",
    "# Uncomment and modify the path to use your own image:\n",
    "# image_path = \"your_image.png\"\n",
    "# img = Image.open(image_path)\n",
    "\n",
    "# Create a simple sample image\n",
    "sample_image = np.random.randint(0, 256, (100, 100), dtype=np.uint8)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title('Sample Image (100x100)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {sample_image.shape}\")\n",
    "print(f\"Image size: {sample_image.size} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress the image\n",
    "image_flat = sample_image.flatten()\n",
    "data = image_flat.tolist()\n",
    "data_str = ''.join([chr(min(255, int(d))) for d in data])\n",
    "\n",
    "df3 = run_comparison(data, data_str, \"Grayscale Image (100x100)\")\n",
    "plot_comparison(df3, \"Grayscale Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7d1f4",
   "metadata": {},
   "source": [
    "## üìÑ Test 3: Document/File Compression\n",
    "\n",
    "Test compression on text files and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample document\n",
    "sample_document = \"\"\"\n",
    "Data Compression Project Report\n",
    "\n",
    "Introduction:\n",
    "Data compression is the process of encoding information using fewer bits than the original representation.\n",
    "Compression can be either lossy or lossless. Lossless compression reduces bits by identifying and eliminating \n",
    "statistical redundancy. No information is lost in lossless compression.\n",
    "\n",
    "Algorithms:\n",
    "1. Run Length Encoding (RLE) - Simple and effective for repetitive data\n",
    "2. Huffman Coding - Variable-length coding based on frequency analysis  \n",
    "3. Lempel-Ziv-Welch (LZW) - Dictionary-based compression algorithm\n",
    "\n",
    "Applications:\n",
    "- File compression (ZIP, GZIP)\n",
    "- Image compression (PNG, GIF)\n",
    "- Video compression (H.264, VP9)\n",
    "- Audio compression (MP3, FLAC)\n",
    "\n",
    "Conclusion:\n",
    "Different compression algorithms excel at different types of data. The choice of algorithm depends on \n",
    "the data characteristics and requirements for compression ratio vs. speed.\n",
    "\"\"\" * 10\n",
    "\n",
    "print(f\"Document length: {len(sample_document)} characters\")\n",
    "print(f\"Preview:\\n{sample_document[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeead57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress the document\n",
    "data = [ord(c) for c in sample_document]\n",
    "df4 = run_comparison(data, sample_document, \"Document Text\")\n",
    "plot_comparison(df4, \"Document Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4eeb02",
   "metadata": {},
   "source": [
    "## üìä Summary: Compare All Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a98f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = pd.concat([\n",
    "    df1.assign(Dataset='Repetitive Text'),\n",
    "    df2.assign(Dataset='Mixed Text'),\n",
    "    df3.assign(Dataset='Image'),\n",
    "    df4.assign(Dataset='Document')\n",
    "], ignore_index=True)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE COMPARISON - ALL DATASETS\")\n",
    "print(\"=\"*100)\n",
    "display(all_results[['Dataset', 'Algorithm', 'Compression Ratio', 'Space Saving %', \n",
    "                     'Compression Time (s)', 'Decompression Time (s)']])\n",
    "\n",
    "# Summary statistics by algorithm\n",
    "print(\"\\nüìà Average Performance by Algorithm:\")\n",
    "summary = all_results.groupby('Algorithm').agg({\n",
    "    'Compression Ratio': 'mean',\n",
    "    'Space Saving %': 'mean',\n",
    "    'Compression Time (s)': 'mean',\n",
    "    'Decompression Time (s)': 'mean'\n",
    "}).round(4)\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization - Overall comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Overall Algorithm Performance Across All Datasets', fontsize=18, fontweight='bold')\n",
    "\n",
    "datasets = all_results['Dataset'].unique()\n",
    "algorithms = all_results['Algorithm'].unique()\n",
    "x = np.arange(len(algorithms))\n",
    "width = 0.2\n",
    "\n",
    "# Plot 1: Compression Ratio by Dataset\n",
    "ax = axes[0, 0]\n",
    "for i, dataset in enumerate(datasets):\n",
    "    data = all_results[all_results['Dataset'] == dataset]['Compression Ratio']\n",
    "    ax.bar(x + i*width, data, width, label=dataset, alpha=0.8)\n",
    "ax.set_ylabel('Compression Ratio')\n",
    "ax.set_title('Compression Ratio by Dataset')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(algorithms)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Space Savings by Dataset\n",
    "ax = axes[0, 1]\n",
    "for i, dataset in enumerate(datasets):\n",
    "    data = all_results[all_results['Dataset'] == dataset]['Space Saving %']\n",
    "    ax.bar(x + i*width, data, width, label=dataset, alpha=0.8)\n",
    "ax.set_ylabel('Space Saving %')\n",
    "ax.set_title('Space Savings by Dataset')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(algorithms)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Average Compression Time\n",
    "ax = axes[1, 0]\n",
    "avg_comp_time = all_results.groupby('Algorithm')['Compression Time (s)'].mean()\n",
    "ax.bar(algorithms, avg_comp_time, color='coral', alpha=0.7)\n",
    "ax.set_ylabel('Average Time (seconds)')\n",
    "ax.set_title('Average Compression Time')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(avg_comp_time):\n",
    "    ax.text(i, v, f'{v:.6f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 4: Average Decompression Time\n",
    "ax = axes[1, 1]\n",
    "avg_decomp_time = all_results.groupby('Algorithm')['Decompression Time (s)'].mean()\n",
    "ax.bar(algorithms, avg_decomp_time, color='purple', alpha=0.7)\n",
    "ax.set_ylabel('Average Time (seconds)')\n",
    "ax.set_title('Average Decompression Time')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(avg_decomp_time):\n",
    "    ax.text(i, v, f'{v:.6f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635a4ba",
   "metadata": {},
   "source": [
    "## üí° Conclusions & Recommendations\n",
    "\n",
    "### Algorithm Characteristics:\n",
    "\n",
    "**RLE (Run Length Encoding)**\n",
    "- ‚úÖ **Best for:** Highly repetitive data, simple graphics, binary images\n",
    "- ‚ö° **Speed:** Very fast compression and decompression\n",
    "- üì¶ **Compression:** Poor on random data, excellent on repetitive data\n",
    "- üéØ **Use when:** Data has long runs of identical values\n",
    "\n",
    "**Huffman Coding**\n",
    "- ‚úÖ **Best for:** Text with varying character frequencies\n",
    "- ‚ö° **Speed:** Moderate (requires building frequency table)\n",
    "- üì¶ **Compression:** Good for text, optimal for frequency-based data\n",
    "- üéØ **Use when:** Need guaranteed lossless compression with good ratio\n",
    "\n",
    "**LZW (Lempel-Ziv-Welch)**\n",
    "- ‚úÖ **Best for:** Text with repeating patterns, general-purpose compression\n",
    "- ‚ö° **Speed:** Good compression speed, excellent decompression\n",
    "- üì¶ **Compression:** Good all-around performance\n",
    "- üéØ **Use when:** Need adaptive dictionary-based compression\n",
    "\n",
    "### Practical Applications:\n",
    "- **Web**: LZW (GIF), Huffman (JPEG metadata)\n",
    "- **Archives**: Huffman + LZ77 (ZIP, GZIP)\n",
    "- **Images**: RLE (BMP), Huffman (JPEG), specialized algorithms (PNG)\n",
    "- **Documents**: LZW or Huffman depending on content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33f0de",
   "metadata": {},
   "source": [
    "## üöÄ Interactive Testing\n",
    "\n",
    "Run the cell below to test compression on your own text input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing\n",
    "def test_custom_input():\n",
    "    \"\"\"Test compression on custom user input.\"\"\"\n",
    "    print(\"Enter your text to compress (or press Enter for default):\")\n",
    "    user_input = input()\n",
    "    \n",
    "    if not user_input:\n",
    "        user_input = \"Hello World! \" * 50\n",
    "        print(f\"Using default text: '{user_input[:50]}...'\")\n",
    "    \n",
    "    print(f\"\\nText length: {len(user_input)} characters\\n\")\n",
    "    \n",
    "    data = [ord(c) for c in user_input]\n",
    "    df = run_comparison(data, user_input, \"Custom Input\")\n",
    "    plot_comparison(df, \"Custom Input\")\n",
    "\n",
    "# Uncomment to run interactive test\n",
    "# test_custom_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bd0a4",
   "metadata": {},
   "source": [
    "## üì¶ Export Results\n",
    "\n",
    "Save your compression results and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"compression_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save all results to CSV\n",
    "all_results.to_csv(f\"{output_dir}/all_results.csv\", index=False)\n",
    "summary.to_csv(f\"{output_dir}/summary_stats.csv\")\n",
    "\n",
    "print(f\"‚úÖ Results saved to '{output_dir}/' directory\")\n",
    "print(f\"   - all_results.csv: Complete test results\")\n",
    "print(f\"   - summary_stats.csv: Summary statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9146d4b",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Project Complete!\n",
    "\n",
    "You've successfully explored data compression algorithms on multiple data types:\n",
    "- ‚úÖ Text strings and documents\n",
    "- ‚úÖ Images\n",
    "- ‚úÖ Performance analysis and comparison\n",
    "- ‚úÖ Visualizations and insights\n",
    "\n",
    "**Next Steps:**\n",
    "1. Try compressing your own files using the `compress.py` script\n",
    "2. Experiment with different data types\n",
    "3. Modify algorithms for specific use cases\n",
    "4. Explore hybrid compression approaches\n",
    "\n",
    "**Author:** Data Compression Project  \n",
    "**Date:** 2025  \n",
    "**License:** MIT"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

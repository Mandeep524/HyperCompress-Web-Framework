# MongoDB Integration Guide

## üéâ Successfully Connected!

Your Data Compression Project is now fully integrated with MongoDB Compass. All compression operations are automatically stored in the database with complete history tracking, file storage, and report generation capabilities.

---

## üìä Database Information

**Connection String:** `mongodb://localhost:27017/`  
**Database Name:** `compression_project`

### Collections

1. **compression_history** - Stores all compression operation records
2. **fs.files** - GridFS metadata for stored files
3. **fs.chunks** - GridFS chunks for large files
4. **files** - File metadata collection

---

## üîå MongoDB Compass Connection

### Connect to Your Database

1. Open **MongoDB Compass**
2. Use connection string: `mongodb://localhost:27017/`
3. Click **Connect**
4. Navigate to database: `compression_project`

### View Your Data

#### Compression History
- **Collection:** `compression_history`
- **Fields:**
  - `filename` - Original file name
  - `file_type` - Type of file (text, image, video, document)
  - `algorithm` - Compression algorithm used (RLE, Huffman, LZW)
  - `original_size` - Size before compression (bytes)
  - `compressed_size` - Size after compression (bytes)
  - `compression_ratio` - Ratio of compressed/original
  - `space_savings` - Percentage saved
  - `compression_time` - Time taken to compress (seconds)
  - `decompression_time` - Time taken to decompress (seconds)
  - `original_file_id` - GridFS ID for original file
  - `compressed_file_id` - GridFS ID for compressed file
  - `timestamp` - When operation occurred

#### Stored Files
- **Collection:** `fs.files`
- View all uploaded original files and compressed outputs
- Files are stored using GridFS for efficient large file handling

---

## üöÄ Features Now Available

### ‚úÖ Implemented

1. **Automatic Database Storage**
   - All text compressions automatically saved
   - Original and compressed files stored in GridFS
   - Full metadata tracking

2. **History Tracking**
   - View all past compressions
   - Filter by algorithm, file type, or date
   - Detailed statistics and metrics

3. **Download Functionality**
   - Download original files
   - Download compressed files
   - All files retrievable by ID

4. **PDF Report Generation**
   - Single compression reports
   - Algorithm comparison reports
   - Full history reports with statistics

5. **Statistics Dashboard**
   - Total compressions count
   - Algorithm breakdown
   - File type distribution
   - Average compression ratios

---

## üåê Web Application Features

### Pages

1. **Home** (`/`) - Welcome and navigation
2. **Text Compression** (`/text`) - Compress text with live preview
3. **Image Compression** (`/images`) - Upload and compress images
4. **Video Compression** (`/videos`) - Upload and compress videos
5. **Document Compression** (`/documents`) - Upload and compress documents
6. **History** (`/history`) - View all compression history

### API Endpoints

#### Compression
- `POST /rle/compress/text` - RLE text compression (‚úÖ DB integrated)
- `POST /huffman/compress/text` - Huffman text compression (‚úÖ DB integrated)
- `POST /lzw/compress/text` - LZW text compression (‚úÖ DB integrated)
- `POST /rle/compress/image` - RLE image compression
- `POST /rle/compress/video` - RLE video compression
- `POST /rle/compress/document` - RLE document compression
- (Similar endpoints for Huffman and LZW)

#### Database Operations
- `GET /api/history` - Get compression history (JSON)
- `GET /api/statistics` - Get statistics (JSON)
- `GET /download/original/<id>` - Download original file
- `GET /download/compressed/<id>` - Download compressed file
- `GET /report/single/<id>` - Generate single compression PDF report
- `GET /report/history` - Generate full history PDF report
- `DELETE /api/delete/<id>` - Delete compression record and files

---

## üß™ Testing the Integration

### 1. Test MongoDB Connection
```bash
.venv/bin/python test_mongodb.py
```

### 2. Test Text Compression with Storage
1. Go to http://localhost:8080/text
2. Enter some text
3. Click any compression algorithm
4. Check MongoDB Compass - new record should appear in `compression_history`
5. Check `fs.files` - two new files (original + compressed)

### 3. View History
1. Go to http://localhost:8080/history
2. See all your compression operations
3. Click "Download Original" or "Download Compressed"
4. Click "Generate Report" for PDF

### 4. Query Database Directly
```bash
mongosh mongodb://localhost:27017/compression_project
```

```javascript
// Get all compression records
db.compression_history.find().pretty()

// Count compressions by algorithm
db.compression_history.aggregate([
  { $group: { _id: "$algorithm", count: { $sum: 1 } } }
])

// Get average compression ratio
db.compression_history.aggregate([
  { $group: { _id: null, avgRatio: { $avg: "$compression_ratio" } } }
])

// List all stored files
db.fs.files.find({}, {filename: 1, length: 1, uploadDate: 1}).pretty()
```

---

## üìà Next Steps

### Remaining Work

1. **Update Image/Video/Document Routes**
   - Add database storage to image compression
   - Add database storage to video compression
   - Add database storage to document compression
   - Update all Huffman and LZW file routes

2. **Enhanced UI**
   - Add download buttons to compression results
   - Show record IDs in results
   - Add "View in History" links

3. **Advanced Features**
   - Comparison mode (compare algorithms side-by-side)
   - Batch compression
   - Export history as CSV
   - Search and filter history

---

## üõ†Ô∏è Database Utility Usage

### In Your Code

```python
from utils.database import CompressionDB

# Initialize
db = CompressionDB()

# Store original file
file_id = db.store_file(
    file_data=b"Your file content",
    filename="myfile.txt",
    file_type="text/plain"
)

# Store compressed file
compressed_id = db.store_compressed_file(
    compressed_data=b"Compressed content",
    filename="myfile.txt",
    algorithm="RLE"
)

# Save compression record
record = {
    'filename': 'myfile.txt',
    'file_type': 'text',
    'algorithm': 'RLE',
    'original_size': 100,
    'compressed_size': 50,
    'compression_ratio': 0.5,
    'space_savings': 50.0,
    'compression_time': 0.001,
    'decompression_time': 0.001,
    'original_file_id': file_id,
    'compressed_file_id': compressed_id
}
record_id = db.save_compression_record(record)

# Retrieve file
file_data = db.get_file(file_id)

# Get history
history = db.get_compression_history(limit=20, algorithm='RLE')

# Get statistics
stats = db.get_statistics()
```

---

## üîç Monitoring

### Check MongoDB Status
```bash
brew services list | grep mongodb
```

### View MongoDB Logs
```bash
tail -f /opt/homebrew/var/log/mongodb/mongo.log
```

### Check Database Size
```javascript
db.stats()
```

---

## üí° Tips

1. **MongoDB Compass** provides excellent visualization of your data
2. Use **indexes** for faster queries on large datasets (already created on `timestamp`, `file_type`, `algorithm`)
3. **GridFS** automatically handles files larger than 16MB
4. **Backup** regularly using `mongodump`
5. Consider adding **TTL indexes** to auto-delete old records

---

## üéØ Current Status

‚úÖ MongoDB connected and running  
‚úÖ Database structure created  
‚úÖ GridFS file storage working  
‚úÖ Text compression routes integrated (RLE, Huffman, LZW)  
‚úÖ History API working  
‚úÖ Download functionality implemented  
‚úÖ PDF report generation working  
‚úÖ Statistics tracking active  

‚è≥ Image/video/document routes need DB integration  
‚è≥ UI needs download buttons  

---

## üìû Support

If you encounter any issues:

1. Check MongoDB is running: `pgrep -fl mongod`
2. Restart MongoDB: `brew services restart mongodb-community`
3. Check Flask server logs for errors
4. Verify connection in MongoDB Compass

Enjoy your fully integrated compression project! üéâ
